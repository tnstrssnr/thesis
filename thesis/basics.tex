\chapter{Theoretical Background}\label{sec:basics}

This chapter presents the theoretical foundations of this thesis. 
% TODO: at least 1 more sentence

\section{Quantitative Information Flow Control}
% Control ?!?!?!

% QIFC
% attacker model
% interpreter inputs
% information + leakage

Information flow security aims to limit the amount of information about a program's secret inputs that can be revealed by its public outputs. Classical information flow analysis tries to prove the absence of such information flows, a property called \emph{non-interference}.
For real world applications, leaking a certain amount of information is often required to build useful programs. In this case, the non-interference property is too strict. Instead we wish to limit the amount of information that is leaked.
Quantitative information flow analysis provides tools to measure how much information can be learned by an attacker about a program's secret inputs.

%%% relevant for this section i.a.:
% On the foundations of quantitative information flow (Smith '09) -- \cite{smith09}
% SAT-Based Analysis and Quantification of Information Flow in Programs (Klebanov et al. '13) -- \cite{klebanov13}
% Quantifiying Dynamic Leakage: Complexity Analysis and Model Counting-based Calculation (Chu et al '19) -- \cite{chu19}
% Quantifying Dynamic Leakage: Complexity Analysis and Model Counting-based Calculation (Besson et al. '16) -- \cite{besson16}
% TODO: add proper citations throughout section

% Nildumu: joana / stand-alone -> API zum AST aufbauen
% was macht dieser Kommentar hier
% vergleiche mal commits der 2 versionen

We consider the following scenario: Given a program \p, that accepts some input \In and produces some output \Out, how much information can an adversary \A learn about $H$, by observing \p and \Out?

%% \paragraph statt \emph
\paragraph{Input program} We assume \p to be a sequential, deterministic program, that receives a set of inputs $\mathtt{H = \{h_1, ..., h_n\}}$ and produces a set of outputs $\mathtt{L = \{l_1, ..., l_m\}}$. Inputs are chosen based on a publicly known a priori probability distribution. Outputs can be produced at any point during the execution. 
We restrict ourselves to analyzing programs that terminate normally. The program text of \p is publicly known.
% TODO: specify scope of language

\paragraph{Security Lattice} Each element of \In and \Out is associated with an element of a security lattice, describing its confidentiality level. We use a lattice with two elements $\hat{l}$, for public values and $\hat{h}$ for secret values.
% Schneider -- nur high und low


\paragraph{Attacker Model} We consider an adversary \A that is able to choose public inputs of \p and observe the resulting outputs on public channels. The attacker is not able to gain information via convert channels, such as timing, storage or resource usage.

%% standard def von min etropy aus smith paper funzt nicht fÃ¼r public inputs
%% new notion (min-entropy ???)
%% handbuch for quantitative information flow

% many leakage measures use average over all possible executions (min entropy, Shannon entropy)
% leakage can differ greatly between different executions --> example algorithm 1
% want to measure amount of information attacker has about the input after a single program execution

\begin{algorithm}
	\caption{} %TODO: caption?  
    \hspace*{\algorithmicindent} \textbf{Input} h: int \\
    \hspace*{\algorithmicindent} \textbf{Output} l: int
	\begin{algorithmic}[1]
        \State $l: int \leftarrow 0$
		\If{$h == 42$}
        \State $l \leftarrow 1$
        \EndIf\\
        \Return l
	\end{algorithmic} 
\end{algorithm}

In \cite{smith09}, Smith characterizes information leakage with the following equation:
\begin{center}
    Initial uncertainty = information leaked + remaining uncertainty.
\end{center}
In our scenario, the unknown value \In is the initial uncertainty, measured by some entropy measure. The remaining uncertainty is the entropy of \In after observing \Out. 

Because programs are deterministic, we can describe the outputs as a function $\phi_p$ of the inputs, thus $\mOut = \phi(\mIn)$. Likewise it holds that $\phi_p^{-1}(\mOut) = \{ \mIn | \phi(\mIn) = \mOut \}$ is the set of all inputs, that produce the same output $\mOut$.

\begin{definition}[Indistinguishability relation]
        bla bla bla
\end{definition}

\section{Model Counting}

Given a propositional formula $F$, the model counting problem (\#SAT) is the problem of finding the number of distinct variable assignments for $F$, for which $F$ evaluates to true \cite{biere09}. So the solution for the formula shown in  \ref{fig:satEx} is \#F = 3, with the only non-fulfilling variable assignments being $\{ x = \mttt, y = \mfff\}, \{x = \mttt, y = \mttt\}$ and  $\{x = \mfff, y = \mfff\}$.

\#SAT is a generalization of the SAT problem and falls into the \#P-complete complexity class, as demonstrated by Valiant in \cite{valiant79}.

Early exact model counting techniques, such as \cite{birnbaum99}, or the well-known tool sharpSAT \cite{thurley06} use a DPLL-style exploration of the solution space. Another class of model counters instead employ complex transformations to turn the given CNF formula into a different representation, which makes model counting a far easier problem. Common are transformations into \emph{binary decision diagrams} (\td{citation!}) or \emph{deterministic, decomposable negation normal form} \cite{darwiche04}.

\paragraph*{Approximate Model Counting}
State-of-the-art exact model counters scale to a couple of hundred variables.  This limit can be pushed to around 1,000 variables if we allow approximate solutions \cite{biere09}.
The first approximate \#SAT algorithm for DNF formulas was introduced by Luby and Karp in \cite{karp89} used Monte-Carlo techniques. This approach was extended to work on CNF formulas by Chakraborty, Meel and Vardi in \cite{chakraborty13}. Bith procedures fall under category of $(\epsilon, \delta)$-counters: for $0 < \epsilon, delta \leq 1$, the approximated solution $\#F_{approx}$ to the true solution of the problem \#F, lies in the interval $[(1 + \epsilon)^{-1} \#F, \: (1 + \epsilon) \#F]$ with a probability of $1 - \delta$ \cite{karp89,chakraborty13}.

\begin{figure}
    \centering
    $F := x \lor \lnot y$
    \caption{Propositional formula with 2 variables}
    \label{fig:satEx}
\end{figure}

\paragraph*{Projected Model Counting}
Given a set of propositional variables $\mathcal{V}$ and a propositional formula $F$ over $\mathcal{V}$, projected model counting (\#$\exists$SAT) is the problem of finding the number of assignments to a set of priority variables $\mathcal{P} \subseteq \mathcal{V}$, such that the assignment can be extended to an assignment over $\mathcal{V}$ that fulfills $F$. Considering the example from \ref{fig:satEx} and a priority set $\mathcal{P} = \{x\}$, the number of projected models is 2, with both possible assignments of $x$ being extendable to a fulfilling assignment over all variables by setting $y = \mfff$.

The problem is introduced by Aziz et.al. in \cite{aziz15}, along with a discussion of approaches to solve \#$\exists$SAT. \td{finish}

\paragraph*{\#SAT in Relation to QIFC}
Model counting has previously been used to tackle QIFC problems \cite{klebanov13, enescu16, biondi18,chu19}. The approach requires the generation of propositional a propositional formula $F_o$, that describes values leaked on public output channels in terms of the program's high input variables.


% Model Counting
% Complexity
% Hashing-based approaches
% Application to CNF
% (\epsilon, \delta) approximation / "Probably Approximately Correct"

%%% relevant for this section
% The Complexity of Enumeration and Reliability Problems (Valiant '79) -- \cite{valiant79}
% A scalable approximate model counter (chakraborty '13) -- \cite{chakraborty13}
